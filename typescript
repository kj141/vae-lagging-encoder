Script started on 2020-05-22 00:57:26-0700
[r[m[2J[H[?7h[?1;4;6l[?1049h[22;0;0t[4l[?1h=[0m(B[1;42r[H[2J[H[2JFirst pass through data to get vocab...
Number of sentences in training: 42068
Number of sentences in valid: 3370
Number of sentences in test: 3761
Vocab size: Original = 9999, Pruned = 10002
3370 3370
Saved 3370 sentences (dropped 0 due to length/unk filter)
3761 3761
Saved 3761 sentences (dropped 0 due to length/unk filter)
42068 42068
Saved 42068 sentences (dropped 0 due to length/unk filter)
Max sent length (before dropping): 84
kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ python preprocess_text.py --trainfile data/ptb/train.txt --valfile data/ptb/val.txt --testfile data/ptb/test.txt --outputfile data/ptb/ptb
First pass through data to get vocab...
Number of sentences in training: 42068
Number of sentences in valid: 3370
Number of sentences in test: 3761
Vocab size: Original = 9999, Pruned = 10002
3370 3370
Saved 3370 sentences (dropped 0 due to length/unk filter)
3761 3761
Saved 3761 sentences (dropped 0 due to length/unk filter)
42068 42068
Saved 42068 sentences (dropped 0 due to length/unk filter)
Max sent length (before dropping): 84
kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ python preprocess_text.py --trainfile data/ptb/train.txt --valfile data/ptb/val.txt --testfile data/ptb/test.txt --outputfile data/ptb/ptb
First pass through data to get vocab...
Number of sentences in training: 42068
Number of sentences in valid: 3370
Number of sentences in test: 3761
Vocab size: Original = 9999, Pruned = 10002
3370 3370
Saved 3370 sentences (dropped 0 due to length/unk filter)
3761 3761
Saved 3761 sentences (dropped 0 due to length/unk filter)
42068 42068
Saved 42068 sentences (dropped 0 due to length/unk filter)
Max sent length (before dropping): 84
kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$[66C  [41;58Hpython train_text_bl_ptb.py --model vae --log_dir logs/ptb/vae_bl
[2020-05-22 00:57:35.970627 PDT] Train data: 1359 batches
[2020-05-22 00:57:35.970941 PDT] Val data: 142 batches
[2020-05-22 00:57:35.971057 PDT] Test data: 155 batches
[2020-05-22 00:57:35.971173 PDT] Word vocab size: 10002
[2020-05-22 00:57:36.275824 PDT] model architecture
RNNVAE(
  (enc_word_vecs): Embedding(10002, 300)
  (latent_linear_mean): Linear(in_features=256, out_features=32, bias=True)
  (latent_linear_logvar): Linear(in_features=256, out_features=32, bias=True)
  (enc_rnn): LSTM(300, 256, batch_first=True)
  (enc): ModuleList(
    (0): Embedding(10002, 300)
    (1): LSTM(300, 256, batch_first=True)
    (2): Linear(in_features=256, out_features=32, bias=True)
    (3): Linear(in_features=256, out_features=32, bias=True)
  )
  (dec_word_vecs): Embedding(10002, 256)
  (dec_rnn): LSTM(288, 256, batch_first=True)
  (dec_linear): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=256, out_features=10002, bias=True)
    (2): LogSoftmax()
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (dec): ModuleList(
    (0): Embedding(10002, 256)
    (1): LSTM(288, 256, batch_first=True)
    (2): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Linear(in_features=256, out_features=10002, bias=True)
      (2): LogSoftmax()
    )
    (3): Linear(in_features=32, out_features=256, bias=True)
  )
  (latent_hidden_linear): Linear(in_features=32, out_features=256, bias=True)
)
[2020-05-22 00:57:40.646227 PDT] Starting epoch 1
/home/kujain/.local/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "train_text_bl_ptb.py", line 389, in <module>
    main(args)
  File "train_text_bl_ptb.py", line 199, in main
    train_nll_vae += nll_vae.data[0]*batch_size
IndexError: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number
kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ conda activate cse291_as2
(cse291_as2) kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ python train_text_bl_ptb.py --model vae --log_dir logss/ptb/vae_bl
Traceback (most recent call last):
  File "train_text_bl_ptb.py", line 27, in <module>
    import logger
  File "/home/kujain/cyclic-vae/language_model/logger.py", line 9, in <module>
    import dateutil.tz
ModuleNotFoundError: No module named 'dateutil'
(cse291_as2) kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ pi [Kp install dateutil
[31mERROR: Could not find a version that satisfies the requirement dateutil (from versions: none)[39m
[31mERROR: No matching distribution found for dateutil[39m
(cse291_as2) kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ pip install python-dateutil
Collecting python-dateutil
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
[?25l[K     |█▍                              | 10 kB 16.6 MB/s eta 0:00:01[K     |██▉                             | 20 kB 13.0 MB/s eta 0:00:01[K     |████▎                           | 30 kB 15.2 MB/s eta 0:00:01[K     |█████▊                          | 40 kB 16.6 MB/s eta 0:00:01[K     |███████▏                        | 51 kB 10.1 MB/s eta 0:00:01[K     |████████▋                       | 61 kB 10.0 MB/s eta 0:00:01[K     |██████████                      | 71 kB 10.2 MB/s eta 0:00:01[K     |███████████▌                    | 81 kB 10.4 MB/s eta 0:00:01[K     |█████████████                   | 92 kB 10.9 MB/s eta 0:00:01[K     |██████████████▍                 | 102 kB 11.5 MB/s eta 0:00:01[K     |███████████████▉                | 112 kB 11.5 MB/s eta 0:00:01[K     |█████████████████▎              | 122 kB 11.5 MB/s eta 0:00:01[K     |██████████████████▊             | 133 kB 11.5 MB/s eta 0:00:01[K     |████████████████████▏           | 143 kB 11.5 MB/s eta 0:00:01[K     |█████████████████████▋          | 153 kB 11.5 MB/s eta 0:00:01[K     |███████████████████████         | 163 kB 11.5 MB/s eta 0:00:01[K     |████████████████████████▌       | 174 kB 11.5 MB/s eta 0:00:01[K     |██████████████████████████      | 184 kB 11.5 MB/s eta 0:00:01[K     |███████████████████████████▍    | 194 kB 11.5 MB/s eta 0:00:01[K     |████████████████████████████▉   | 204 kB 11.5 MB/s eta 0:00:01[K     |██████████████████████████████▎ | 215 kB 11.5 MB/s eta 0:00:01[K     |███████████████████████████████▊| 225 kB 11.5 MB/s eta 0:00:01[K     |████████████████████████████████| 227 kB 11.5 MB/s 
[?12l[?25hRequirement already satisfied: six>=1.5 in /home/kujain/.conda/envs/cse291_as2/lib/python3.6/site-packages (from python-dateutil) (1.14.0)
Installing collected packages: python-dateutil
Successfully installed python-dateutil-2.8.1
(cse291_as2) kujain@dsmlp-jupyter-kujain:~/cyclic-vae/language_model$ pip install python-dateutil[7Pdateutilython train_text_bl_ptb.py --model vae --log_dir logss/ptb/vae_bl
[2020-05-22 00:58:48.221186 PDT] Train data: 1359 batches
[2020-05-22 00:58:48.221483 PDT] Val data: 142 batches
[2020-05-22 00:58:48.221629 PDT] Test data: 155 batches
[2020-05-22 00:58:48.221744 PDT] Word vocab size: 10002
[2020-05-22 00:58:48.911856 PDT] model architecture
RNNVAE(
  (enc_word_vecs): Embedding(10002, 300)
  (latent_linear_mean): Linear(in_features=256, out_features=32, bias=True)
  (latent_linear_logvar): Linear(in_features=256, out_features=32, bias=True)
  (enc_rnn): LSTM(300, 256, batch_first=True)
  (enc): ModuleList(
    (0): Embedding(10002, 300)
    (1): LSTM(300, 256, batch_first=True)
    (2): Linear(in_features=256, out_features=32, bias=True)
    (3): Linear(in_features=256, out_features=32, bias=True)
  )
  (dec_word_vecs): Embedding(10002, 256)
  (dec_rnn): LSTM(288, 256, batch_first=True)
  (dec_linear): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=256, out_features=10002, bias=True)
    (2): LogSoftmax()
  )
  (dropout): Dropout(p=0.5)
  (dec): ModuleList(
    (0): Embedding(10002, 256)
    (1): LSTM(288, 256, batch_first=True)
    (2): Sequential(
      (0): Dropout(p=0.5)
      (1): Linear(in_features=256, out_features=10002, bias=True)
      (2): LogSoftmax()
    )
    (3): Linear(in_features=32, out_features=256, bias=True)
  )
  (latent_hidden_linear): Linear(in_features=32, out_features=256, bias=True)
)
[2020-05-22 00:58:53.735241 PDT] Starting epoch 1
/home/kujain/.conda/envs/cse291_as2/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[2020-05-22 00:58:56.680135 PDT] Iters: 0, Epoch: 1, Batch: 101/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 172.8984, TrainVAE_REC: 166.6746, TrainVAE_KL: 6.2237, TrainVAE_PPL: 1852.21, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 191.8762, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1074, Throughput: 1059.79 examples/sec
[2020-05-22 00:58:58.895544 PDT] Iters: 0, Epoch: 1, Batch: 201/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 157.5794, TrainVAE_REC: 153.5502, TrainVAE_KL: 4.0292, TrainVAE_PPL: 1171.92, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 213.5195, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1147, Throughput: 1204.18 examples/sec
[2020-05-22 00:59:00.991488 PDT] Iters: 0, Epoch: 1, Batch: 301/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 150.5193, TrainVAE_REC: 147.3066, TrainVAE_KL: 3.2127, TrainVAE_PPL: 934.78, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 231.2370, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1221, Throughput: 1280.28 examples/sec
[2020-05-22 00:59:03.256662 PDT] Iters: 0, Epoch: 1, Batch: 401/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 146.7407, TrainVAE_REC: 143.9300, TrainVAE_KL: 2.8107, TrainVAE_PPL: 798.64, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 244.3408, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1294, Throughput: 1300.86 examples/sec
[2020-05-22 00:59:05.234143 PDT] Iters: 0, Epoch: 1, Batch: 501/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 141.5773, TrainVAE_REC: 138.9753, TrainVAE_KL: 2.6020, TrainVAE_PPL: 718.50, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 254.0885, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1368, Throughput: 1348.56 examples/sec
[2020-05-22 00:59:07.552174 PDT] Iters: 0, Epoch: 1, Batch: 601/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 140.3620, TrainVAE_REC: 137.8777, TrainVAE_KL: 2.4843, TrainVAE_PPL: 655.52, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 262.4940, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1442, Throughput: 1346.03 examples/sec
[2020-05-22 00:59:09.920465 PDT] Iters: 0, Epoch: 1, Batch: 701/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 139.3417, TrainVAE_REC: 136.9080, TrainVAE_KL: 2.4337, TrainVAE_PPL: 610.19, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 269.4166, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1515, Throughput: 1339.00 examples/sec
[2020-05-22 00:59:12.356628 PDT] Iters: 0, Epoch: 1, Batch: 801/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 138.2344, TrainVAE_REC: 135.8314, TrainVAE_KL: 2.4030, TrainVAE_PPL: 571.73, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 275.2478, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1589, Throughput: 1333.25 examples/sec
[2020-05-22 00:59:14.734873 PDT] Iters: 0, Epoch: 1, Batch: 901/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 137.3024, TrainVAE_REC: 134.9064, TrainVAE_KL: 2.3960, TrainVAE_PPL: 543.17, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 280.5436, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1662, Throughput: 1329.84 examples/sec
[2020-05-22 00:59:17.039380 PDT] Iters: 0, Epoch: 1, Batch: 1001/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 136.8698, TrainVAE_REC: 134.4523, TrainVAE_KL: 2.4175, TrainVAE_PPL: 517.64, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 285.1664, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1736, Throughput: 1328.95 examples/sec
[2020-05-22 00:59:19.586185 PDT] Iters: 0, Epoch: 1, Batch: 1101/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 137.2693, TrainVAE_REC: 134.8385, TrainVAE_KL: 2.4309, TrainVAE_PPL: 496.68, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 289.4709, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1809, Throughput: 1317.98 examples/sec
[2020-05-22 00:59:21.982186 PDT] Iters: 0, Epoch: 1, Batch: 1201/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 136.4981, TrainVAE_REC: 134.0427, TrainVAE_KL: 2.4554, TrainVAE_PPL: 479.25, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 293.3121, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1883, Throughput: 1318.48 examples/sec
[2020-05-22 00:59:24.442804 PDT] Iters: 0, Epoch: 1, Batch: 1301/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 135.8133, TrainVAE_REC: 133.3426, TrainVAE_KL: 2.4706, TrainVAE_PPL: 464.00, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 296.7024, BestValPerf: 100000.00, BestEpoch: 0, Beta: 0.1957, Throughput: 1310.36 examples/sec
[2020-05-22 00:59:25.795406 PDT] Time Elapsed: 32.1s
[2020-05-22 00:59:25.795684 PDT] --------------------------------
[2020-05-22 00:59:25.795935 PDT] Checking validation perf...
-------------------------------
| Epoch            | 1        |
| Mode             | Val      |
| LR               | 0.001    |
| Epoch Train Time | 32.06    |
| AR NLL           | 0        |
| AR PPL           | 1        |
| VAE NLL          | 121.96   |
| VAE REC          | 119.13   |
| VAE KL           | 2.833    |
| VAE PPL          | 263.03   |
| SVI NLL          | 0        |
| SVI REC          | 0        |
| SVI KL           | 0        |
| SVI PPL          | 1        |
-------------------------------
[2020-05-22 00:59:26.707312 PDT] AR NLL: 0.0000, AR PPL: 1.0000, VAE NLL: 121.9616, VAE REC: 119.1286, VAE KL: 2.8330, VAE PPL: 263.0302, SVI NLL: 0.0000, SVI REC: 0.0000, SVI KL: 0.0000, SVI PPL: 1.0000
[2020-05-22 00:59:26.707897 PDT] --------------------------------
[2020-05-22 00:59:26.708050 PDT] Checking test perf...
-------------------------------
| Epoch            | 1        |
| Mode             | Test     |
| LR               | 0.001    |
| Epoch Train Time | 32.06    |
| AR NLL           | 0        |
| AR PPL           | 1        |
| VAE NLL          | 120.89   |
| VAE REC          | 118.15   |
| VAE KL           | 2.7457   |
| VAE PPL          | 248.6    |
| SVI NLL          | 0        |
| SVI REC          | 0        |
| SVI KL           | 0        |
| SVI PPL          | 1        |
-------------------------------
[2020-05-22 00:59:27.720736 PDT] AR NLL: 0.0000, AR PPL: 1.0000, VAE NLL: 120.8910, VAE REC: 118.1452, VAE KL: 2.7457, VAE PPL: 248.5994, SVI NLL: 0.0000, SVI REC: 0.0000, SVI KL: 0.0000, SVI PPL: 1.0000
[2020-05-22 00:59:27.805170 PDT] Save checkpoint to models/ptb/vae_bl.pt
[2020-05-22 00:59:27.945596 PDT] Starting epoch 2
/home/kujain/.conda/envs/cse291_as2/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[2020-05-22 00:59:30.194923 PDT] Iters: 0, Epoch: 2, Batch: 101/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 120.6424, TrainVAE_REC: 117.8605, TrainVAE_KL: 2.7819, TrainVAE_PPL: 286.29, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 301.8490, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2074, Throughput: 1384.88 examples/sec
[2020-05-22 00:59:32.407775 PDT] Iters: 0, Epoch: 2, Batch: 201/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 120.5870, TrainVAE_REC: 117.7970, TrainVAE_KL: 2.7899, TrainVAE_PPL: 277.74, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 304.9381, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2147, Throughput: 1393.29 examples/sec
[2020-05-22 00:59:34.861155 PDT] Iters: 0, Epoch: 2, Batch: 301/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 122.8058, TrainVAE_REC: 119.8954, TrainVAE_KL: 2.9105, TrainVAE_PPL: 274.25, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 307.9690, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2221, Throughput: 1338.88 examples/sec
[2020-05-22 00:59:37.295389 PDT] Iters: 0, Epoch: 2, Batch: 401/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 123.6871, TrainVAE_REC: 120.6608, TrainVAE_KL: 3.0263, TrainVAE_PPL: 273.56, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 310.9230, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2294, Throughput: 1323.36 examples/sec
[2020-05-22 00:59:39.700828 PDT] Iters: 0, Epoch: 2, Batch: 501/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 124.4728, TrainVAE_REC: 121.3577, TrainVAE_KL: 3.1152, TrainVAE_PPL: 271.44, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 313.7090, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2368, Throughput: 1315.59 examples/sec
[2020-05-22 00:59:41.941908 PDT] Iters: 0, Epoch: 2, Batch: 601/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 122.4501, TrainVAE_REC: 119.1906, TrainVAE_KL: 3.2595, TrainVAE_PPL: 269.45, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 316.2533, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2442, Throughput: 1329.50 examples/sec
[2020-05-22 00:59:44.184672 PDT] Iters: 0, Epoch: 2, Batch: 701/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 121.6270, TrainVAE_REC: 118.2733, TrainVAE_KL: 3.3537, TrainVAE_PPL: 267.35, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 318.6473, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2515, Throughput: 1334.25 examples/sec
[2020-05-22 00:59:46.507258 PDT] Iters: 0, Epoch: 2, Batch: 801/1359, LR: 0.0010, TrainARNLL: 0.0000, TrainARPPL: 1.00, TrainVAE_NLL: 121.8296, TrainVAE_REC: 118.4037, TrainVAE_KL: 3.4259, TrainVAE_PPL: 264.68, TrainSVI_NLL: 0.00, TrainSVI_REC: 0.00, TrainSVI_KL: 0.0000, TrainSVI_PPL: 1.00, KLInitFinal: 0.00, |Param|: 321.0041, BestValPerf: 263.03, BestEpoch: 1, Beta: 0.2589, Throughput: 1337.22 examples/sec
[?1l>[42;1H
[?1049l[23;0;0t[detached from 7085.pts-1.dsmlp-jupyter-kujain]
[7mUtmp slot not found -> not removed[27m                                      
Script done on 2020-05-22 00:59:48-0700
